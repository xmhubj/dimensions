# Hyperparameters

- alpha (most important, 1st)
- beta (2nd)
- beta1, beta2, epsilon (Adam, 0.9, 0.999, 10^8)
- number of layers (3rd)
- number of layer units (2nd)
- learning rate decay (3rd)
- mini-batch size (2nd)


# Hyperparameters search

- Try random values: Don't use a grid
- Coarse to fine
- Radom sampling
- Adequate searching
- Appropriate/right scale for hyperparameters

#  
